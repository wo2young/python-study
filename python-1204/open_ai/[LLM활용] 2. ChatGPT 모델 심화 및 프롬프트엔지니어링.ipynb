{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9ea9f549",
      "metadata": {},
      "source": [
        "# OpenAI API 강의 2\n",
        "## 주제: ChatGPT 모델 심화 및 프롬프트 엔지니어링"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b59af7f6",
      "metadata": {},
      "source": [
        "\n",
        "## 학습 목표\n",
        "- ChatGPT 모델 구조 및 기능 이해\n",
        "- 프롬프트 엔지니어링 기법 실습\n",
        "- System / User / Assistant 역할의 차이 학습\n",
        "- 다양한 프롬프트 스타일 비교 (지시형, 예시형, Few-shot 등)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ff326a4",
      "metadata": {},
      "source": [
        "\n",
        "## 1. ChatGPT 모델 개요\n",
        "| 항목 | 설명 |\n",
        "|------|------|\n",
        "| 모델 이름 | `gpt-4.1`, `gpt-4o-mini`, `gpt-3.5-turbo` 등 |\n",
        "| 모델 특징 | 대화형 자연어 처리에 최적화 |\n",
        "| 주요 기능 | 대화 유지, 문맥 기억, 다양한 역할(System/User/Assistant) |\n",
        "| 활용 예시 | 챗봇, 고객지원, 문서 요약, 질의응답, 코드 보조 |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "25382192",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adam(Adaptive Moment Estimation)은 딥러닝에서 널리 사용되는 최적화 알고리즘 중 하나입니다. 주로 신경망의 가중치를 업데이트하는 데 사용되며, 다음과 같은 특징을 가지고 있습니다.\n",
            "\n",
            "### Adam의 주요 특징:\n",
            "1. **Adaptive Learning Rates**: Adam은 각 매개변수에 대해 개별적으로 학습률을 조정합니다. 이는 다양한 특성을 가진 파라미터를 효과적으로 학습할 수 있도록 합니다.\n",
            "\n",
            "2. **1차 모멘트와 2차 모멘트**: Adam은 기울기(gradient)와 그 기울기의 제곱의 지수 감소 평균을 사용합니다. 이를 통해 적응형 학습률을 계산하는데, \n",
            "   - \\( m_t \\)는 기울기의 지수 감소 평균 (1차 모멘트)\n",
            "   - \\( v_t \\)는 기울기의 제곱의 지수 감소 평균 (2차 모멘트)입니다.\n",
            "\n",
            "3. **편향 보정**: Adam은 초기에는 평균과 분산 추정치가 편향될 수 있으므로, 이를 보정하기 위한 방법을 포함하고 있습니다. 이는 각 모멘트 추정치에 대해 \\( \\hat{m}_t \\)와 \\( \\hat{v}_t \\)라는 보정된 값을 계산하여 사용합니다.\n",
            "\n",
            "### Adam 업데이트 공식:\n",
            "Adam 최적화는 다음과 같은 절차로 이루어집니다.\n",
            "\n",
            "1. **1차 모멘트**: \n",
            "   \\[\n",
            "   m_t = \\beta_1 m_{t-1} + (1 - \\beta_1) g_t\n",
            "   \\]\n",
            "\n",
            "2. **2차 모멘트**:\n",
            "   \\[\n",
            "   v_t = \\beta_2 v_{t-1} + (1 - \\beta_2) g_t^2\n",
            "   \\]\n",
            "\n",
            "3. **편향 보정**:\n",
            "   \\[\n",
            "   \\hat{m}_t = \\frac{m_t}{1 - \\beta_1^t}, \\quad \\hat{v}_t = \\frac{v_t}{1 - \\beta_2^t}\n",
            "   \\]\n",
            "\n",
            "4. **가중치 업데이트**:\n",
            "   \\[\n",
            "   \\theta_{t} = \\theta_{t-1} - \\frac{\\alpha}{\\sqrt{\\hat{v}_t} + \\epsilon} \\hat{m}_t\n",
            "   \\]\n",
            "   여기서 \\( \\alpha \\)는 학습률, \\( \\epsilon \\)은 0으로 나누는 것을 방지하기 위한 작은 값입니다.\n",
            "\n",
            "### 장점:\n",
            "- **빠른 수렴**: Adam은 일반적으로 빠른 학습 속도를 자랑합니다.\n",
            "- **적응형 메커니즘**: 각 파라미터에 대해 다르게 학습률을 조정함으로써 더 안정적인 학습을 제공합니다.\n",
            "- **적은 메모리 요구**: 다른 몇 가지 최적화 방법에 비해 메모리 사용량이 적습니다.\n",
            "\n",
            "### 단점:\n",
            "- 때때로 Adam이 최적의 해에 수렴하지 않는 경우도 있습니다. 특정 경우에 다른 최적화 알고리즘이 더 나은 성능을 보일 수 있습니다.\n",
            "\n",
            "Adam은 다양한 딥러닝 프레임워크에서 쉽게 구현되어 있으며, 편리함과 효율성 덕분에 많은 실제 문제에 사용되고 있습니다.\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"너는 친절한 AI 강사야.\"},\n",
        "        {\"role\": \"user\", \"content\": \"딥러닝에서 나오는 adam에 대해 설명해줘.\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "print(response.choices[0].message.content)\n",
        "markdown_doc = response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3cc2c78d",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "Adam(Adaptive Moment Estimation)은 딥러닝에서 널리 사용되는 최적화 알고리즘 중 하나입니다. 주로 신경망의 가중치를 업데이트하는 데 사용되며, 다음과 같은 특징을 가지고 있습니다.\n",
              "\n",
              "### Adam의 주요 특징:\n",
              "1. **Adaptive Learning Rates**: Adam은 각 매개변수에 대해 개별적으로 학습률을 조정합니다. 이는 다양한 특성을 가진 파라미터를 효과적으로 학습할 수 있도록 합니다.\n",
              "\n",
              "2. **1차 모멘트와 2차 모멘트**: Adam은 기울기(gradient)와 그 기울기의 제곱의 지수 감소 평균을 사용합니다. 이를 통해 적응형 학습률을 계산하는데, \n",
              "   - \\( m_t \\)는 기울기의 지수 감소 평균 (1차 모멘트)\n",
              "   - \\( v_t \\)는 기울기의 제곱의 지수 감소 평균 (2차 모멘트)입니다.\n",
              "\n",
              "3. **편향 보정**: Adam은 초기에는 평균과 분산 추정치가 편향될 수 있으므로, 이를 보정하기 위한 방법을 포함하고 있습니다. 이는 각 모멘트 추정치에 대해 \\( \\hat{m}_t \\)와 \\( \\hat{v}_t \\)라는 보정된 값을 계산하여 사용합니다.\n",
              "\n",
              "### Adam 업데이트 공식:\n",
              "Adam 최적화는 다음과 같은 절차로 이루어집니다.\n",
              "\n",
              "1. **1차 모멘트**: \n",
              "   \\[\n",
              "   m_t = \\beta_1 m_{t-1} + (1 - \\beta_1) g_t\n",
              "   \\]\n",
              "\n",
              "2. **2차 모멘트**:\n",
              "   \\[\n",
              "   v_t = \\beta_2 v_{t-1} + (1 - \\beta_2) g_t^2\n",
              "   \\]\n",
              "\n",
              "3. **편향 보정**:\n",
              "   \\[\n",
              "   \\hat{m}_t = \\frac{m_t}{1 - \\beta_1^t}, \\quad \\hat{v}_t = \\frac{v_t}{1 - \\beta_2^t}\n",
              "   \\]\n",
              "\n",
              "4. **가중치 업데이트**:\n",
              "   \\[\n",
              "   \\theta_{t} = \\theta_{t-1} - \\frac{\\alpha}{\\sqrt{\\hat{v}_t} + \\epsilon} \\hat{m}_t\n",
              "   \\]\n",
              "   여기서 \\( \\alpha \\)는 학습률, \\( \\epsilon \\)은 0으로 나누는 것을 방지하기 위한 작은 값입니다.\n",
              "\n",
              "### 장점:\n",
              "- **빠른 수렴**: Adam은 일반적으로 빠른 학습 속도를 자랑합니다.\n",
              "- **적응형 메커니즘**: 각 파라미터에 대해 다르게 학습률을 조정함으로써 더 안정적인 학습을 제공합니다.\n",
              "- **적은 메모리 요구**: 다른 몇 가지 최적화 방법에 비해 메모리 사용량이 적습니다.\n",
              "\n",
              "### 단점:\n",
              "- 때때로 Adam이 최적의 해에 수렴하지 않는 경우도 있습니다. 특정 경우에 다른 최적화 알고리즘이 더 나은 성능을 보일 수 있습니다.\n",
              "\n",
              "Adam은 다양한 딥러닝 프레임워크에서 쉽게 구현되어 있으며, 편리함과 효율성 덕분에 많은 실제 문제에 사용되고 있습니다."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from IPython.display import Markdown, display\n",
        "Markdown(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "208b3307",
      "metadata": {},
      "source": [
        "\n",
        "## 2. 역할(Role)의 이해\n",
        "| Role | 설명 | 예시 |\n",
        "|------|------|------|\n",
        "| system | 모델의 성격과 역할을 정의 | \"너는 데이터 분석 전문가야.\" |\n",
        "| user | 사용자의 질문이나 요청 | \"데이터 시각화 코드를 작성해줘.\" |\n",
        "| assistant | 모델이 생성한 응답 | \"다음은 matplotlib을 활용한 코드야...\" |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59cc14ac",
      "metadata": {},
      "source": [
        "\n",
        "## 3. 프롬프트 엔지니어링 기법\n",
        "| 기법 | 설명 | 예시 |\n",
        "|------|------|------|\n",
        "| 지시형 (Instruction) | 명확한 지시문 형태로 요청 | \"Python으로 파일 읽는 코드를 작성해줘.\" |\n",
        "| 예시형 (Example-based) | 예시를 통해 출력 패턴 유도 | \"입력: 사과 → 출력: Apple\" |\n",
        "| Few-shot | 여러 예시로 패턴 학습 유도 | \"입력: 고양이→Cat, 입력: 강아지→Dog\" |\n",
        "| Chain-of-Thought | 단계별 사고 유도 | \"단계별로 이유를 설명하면서 답변해줘.\" |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "4629ecbe",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adam (Adaptive Moment Estimation) is one of the widely used optimization algorithms in deep learning. Proposed in 2014, Adam provides a lightweight learning rate and helps convergence more quickly and effectively than traditional methods like SGD (Stochastic Gradient Descent).\n",
            "\n",
            "The main features of Adam are as follows:\n",
            "\n",
            "1. **Adaptive Learning Rate**: Adam adjusts the learning rate individually for each parameter, allowing for more efficient parameter updates.\n",
            "\n",
            "2. **Momentum**: Adam incorporates the concept of momentum by considering previous gradients. This enables lightweight updates and reduces the problem of getting stuck in local minima.\n",
            "\n",
            "3. **Two Exponential Moving Averages**:\n",
            "   - **First Moment**: Represents the average of the gradients and acts as a type of momentum.\n",
            "   - **Second Moment**: Represents the average of the squared gradients, reflecting the magnitude of changes for each parameter.\n",
            "\n",
            "4. **Bias-Correction**: To address the issue of initial momentum estimates being close to zero, Adam employs a bias correction technique to adjust for imbalances in the early stages.\n",
            "\n",
            "The update formulas for Adam are as follows:\n",
            "\n",
            "1. \\( m_t = \\beta_1 m_{t-1} + (1 - \\beta_1) g_t \\)\n",
            "2. \\( v_t = \\beta_2 v_{t-1} + (1 - \\beta_2) g_t^2 \\)\n",
            "3. \\( \\hat{m}_t = \\frac{m_t}{1 - \\beta_1^t} \\)\n",
            "4. \\( \\hat{v}_t = \\frac{v_t}{1 - \\beta_2^t} \\)\n",
            "5. \\( \\theta_{t+1} = \\theta_t - \\frac{\\eta}{\\sqrt{\\hat{v}_t} + \\epsilon} \\hat{m}_t \\)\n",
            "\n",
            "Where:\n",
            "- \\( g_t \\) is the gradient at the current step,\n",
            "- \\( m_t \\) is the first moment,\n",
            "- \\( v_t \\) is the second moment,\n",
            "- \\( \\beta_1 \\) and \\( \\beta_2 \\) are coefficients typically set to 0.9 and 0.999 for momentum,\n",
            "- \\( \\epsilon \\) is a small value for numerical stability.\n",
            "\n",
            "Thus, Adam is effective in solving various types of optimization problems and has become a very popular choice in multiple deep learning models.\n"
          ]
        }
      ],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"너는 번역가야.\"},\n",
        "        # {\"role\": \"user\", \"content\": \"입력: 안녕하세요 → 출력:\"}\n",
        "        {\"role\": \"user\", \"content\": f\"입력: {markdown_doc} → 출력:\"}\n",
        "    ]\n",
        ")\n",
        "print(response.choices[0].message.content)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "65243270",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "Adam (Adaptive Moment Estimation) is one of the widely used optimization algorithms in deep learning. Proposed in 2014, Adam provides a lightweight learning rate and helps convergence more quickly and effectively than traditional methods like SGD (Stochastic Gradient Descent).\n",
              "\n",
              "The main features of Adam are as follows:\n",
              "\n",
              "1. **Adaptive Learning Rate**: Adam adjusts the learning rate individually for each parameter, allowing for more efficient parameter updates.\n",
              "\n",
              "2. **Momentum**: Adam incorporates the concept of momentum by considering previous gradients. This enables lightweight updates and reduces the problem of getting stuck in local minima.\n",
              "\n",
              "3. **Two Exponential Moving Averages**:\n",
              "   - **First Moment**: Represents the average of the gradients and acts as a type of momentum.\n",
              "   - **Second Moment**: Represents the average of the squared gradients, reflecting the magnitude of changes for each parameter.\n",
              "\n",
              "4. **Bias-Correction**: To address the issue of initial momentum estimates being close to zero, Adam employs a bias correction technique to adjust for imbalances in the early stages.\n",
              "\n",
              "The update formulas for Adam are as follows:\n",
              "\n",
              "1. \\( m_t = \\beta_1 m_{t-1} + (1 - \\beta_1) g_t \\)\n",
              "2. \\( v_t = \\beta_2 v_{t-1} + (1 - \\beta_2) g_t^2 \\)\n",
              "3. \\( \\hat{m}_t = \\frac{m_t}{1 - \\beta_1^t} \\)\n",
              "4. \\( \\hat{v}_t = \\frac{v_t}{1 - \\beta_2^t} \\)\n",
              "5. \\( \\theta_{t+1} = \\theta_t - \\frac{\\eta}{\\sqrt{\\hat{v}_t} + \\epsilon} \\hat{m}_t \\)\n",
              "\n",
              "Where:\n",
              "- \\( g_t \\) is the gradient at the current step,\n",
              "- \\( m_t \\) is the first moment,\n",
              "- \\( v_t \\) is the second moment,\n",
              "- \\( \\beta_1 \\) and \\( \\beta_2 \\) are coefficients typically set to 0.9 and 0.999 for momentum,\n",
              "- \\( \\epsilon \\) is a small value for numerical stability.\n",
              "\n",
              "Thus, Adam is effective in solving various types of optimization problems and has become a very popular choice in multiple deep learning models."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Markdown(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "761d73e4",
      "metadata": {},
      "source": [
        "\n",
        "## 4. 다양한 프롬프트 스타일 비교\n",
        "### (1) 지시형 프롬프트\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "504841ce",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "물론입니다! 아래는 인공지능(AI)의 장단점을 정리한 표입니다.\n",
            "\n",
            "| 장점                                   | 단점                                   |\n",
            "|--------------------------------------|--------------------------------------|\n",
            "| 1. 효율성 향상                          | 1. 일자리 감소                         |\n",
            "| 2. 반복적인 작업 자동화                | 2. 높은 초기 투자 비용                 |\n",
            "| 3. 데이터 분석 및 의사결정 지원       | 3. 데이터 품질에 따른 문제 발생 가능  |\n",
            "| 4. 24/7 지속적인 작업 가능            | 4. 윤리적 문제 및 책임 소재 불명확    |\n",
            "| 5. 인간의 실수 감소                   | 5. 예측 불가능한 행동 가능성          |\n",
            "| 6. 개인화된 서비스 제공                | 6. 개인정보 보호 문제                  |\n",
            "| 7. 다양한 분야에서의 활용 가능        | 7. 기술 의존도 증가                    |\n",
            "\n",
            "이 표는 인공지능의 주요 장점과 단점을 간략하게 정리한 것입니다. 각 항목은 상황에 따라 달라질 수 있습니다.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "prompt = \"인공지능의 장단점을 표로 정리해줘.\"\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        ")\n",
        "print(response.choices[0].message.content)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "772e8275",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "물론입니다! 아래는 인공지능(AI)의 장단점을 정리한 표입니다.\n",
              "\n",
              "| 장점                                   | 단점                                   |\n",
              "|--------------------------------------|--------------------------------------|\n",
              "| 1. 효율성 향상                          | 1. 일자리 감소                         |\n",
              "| 2. 반복적인 작업 자동화                | 2. 높은 초기 투자 비용                 |\n",
              "| 3. 데이터 분석 및 의사결정 지원       | 3. 데이터 품질에 따른 문제 발생 가능  |\n",
              "| 4. 24/7 지속적인 작업 가능            | 4. 윤리적 문제 및 책임 소재 불명확    |\n",
              "| 5. 인간의 실수 감소                   | 5. 예측 불가능한 행동 가능성          |\n",
              "| 6. 개인화된 서비스 제공                | 6. 개인정보 보호 문제                  |\n",
              "| 7. 다양한 분야에서의 활용 가능        | 7. 기술 의존도 증가                    |\n",
              "\n",
              "이 표는 인공지능의 주요 장점과 단점을 간략하게 정리한 것입니다. 각 항목은 상황에 따라 달라질 수 있습니다."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Markdown(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d4f720c",
      "metadata": {},
      "source": [
        "### (2) Few-shot 프롬프트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "33b578c0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "book\n"
          ]
        }
      ],
      "source": [
        "\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"너는 한국어-영어 번역가야.\"},\n",
        "    {\"role\": \"user\", \"content\": \"입력: 학교 → 출력: school\"},\n",
        "    {\"role\": \"user\", \"content\": \"입력: 책 → 출력:\"}\n",
        "]\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=messages\n",
        ")\n",
        "print(response.choices[0].message.content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "280035c9",
      "metadata": {},
      "source": [
        "\n",
        "## 5. 실습 과제\n",
        "1. 자신이 선택한 직업(예: 데이터 분석가, 마케터, 개발자)에 맞는 system role을 설정해보세요.\n",
        "2. 3가지 프롬프트 기법(지시형, 예시형, few-shot)을 각각 적용해 보세요.\n",
        "3. 어떤 방식이 가장 좋은 결과를 주었는지 토의해 봅시다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "713f4ac3",
      "metadata": {},
      "source": [
        "\n",
        "## 참고 자료\n",
        "- [OpenAI Chat Completions API Docs](https://platform.openai.com/docs/api-reference/chat)\n",
        "- [Prompt Engineering Guide](https://www.promptingguide.ai/)\n",
        "- [OpenAI Cookbook - Prompt Design](https://github.com/openai/openai-cookbook)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "py310",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
